{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1187,"sourceType":"datasetVersion","datasetId":626},{"sourceId":22587,"sourceType":"datasetVersion","datasetId":17200}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nizarbousabat/movie-recommendation-system-project?scriptVersionId=212916812\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:28.466936Z","iopub.execute_input":"2024-12-13T15:24:28.467297Z","iopub.status.idle":"2024-12-13T15:24:29.501361Z","shell.execute_reply.started":"2024-12-13T15:24:28.467258Z","shell.execute_reply":"2024-12-13T15:24:29.500324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Reading the main datasets","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'movie_id', 'rating','timestamp'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.502893Z","iopub.execute_input":"2024-12-13T15:24:29.503225Z","iopub.status.idle":"2024-12-13T15:24:29.584299Z","shell.execute_reply.started":"2024-12-13T15:24:29.503199Z","shell.execute_reply":"2024-12-13T15:24:29.583474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.585234Z","iopub.execute_input":"2024-12-13T15:24:29.585513Z","iopub.status.idle":"2024-12-13T15:24:29.601639Z","shell.execute_reply.started":"2024-12-13T15:24:29.585484Z","shell.execute_reply":"2024-12-13T15:24:29.600852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.603728Z","iopub.execute_input":"2024-12-13T15:24:29.604397Z","iopub.status.idle":"2024-12-13T15:24:29.613439Z","shell.execute_reply.started":"2024-12-13T15:24:29.60437Z","shell.execute_reply":"2024-12-13T15:24:29.612483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_info=pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.info', sep='\\t', header=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.614602Z","iopub.execute_input":"2024-12-13T15:24:29.614978Z","iopub.status.idle":"2024-12-13T15:24:29.630381Z","shell.execute_reply.started":"2024-12-13T15:24:29.614939Z","shell.execute_reply":"2024-12-13T15:24:29.629436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_info.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.631993Z","iopub.execute_input":"2024-12-13T15:24:29.632299Z","iopub.status.idle":"2024-12-13T15:24:29.642312Z","shell.execute_reply.started":"2024-12-13T15:24:29.632265Z","shell.execute_reply":"2024-12-13T15:24:29.641417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"column_names = [ 'movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western' ] \n# Read the file \ndf_items = pd.read_csv( '/kaggle/input/movielens-100k-dataset/ml-100k/u.item', sep='|', header=None, names=column_names, encoding='ISO-8859-1' )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.643474Z","iopub.execute_input":"2024-12-13T15:24:29.643827Z","iopub.status.idle":"2024-12-13T15:24:29.680994Z","shell.execute_reply.started":"2024-12-13T15:24:29.643788Z","shell.execute_reply":"2024-12-13T15:24:29.680111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_items.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.682111Z","iopub.execute_input":"2024-12-13T15:24:29.682447Z","iopub.status.idle":"2024-12-13T15:24:29.704725Z","shell.execute_reply.started":"2024-12-13T15:24:29.68241Z","shell.execute_reply":"2024-12-13T15:24:29.703969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_genre=pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.genre', sep='|', header=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.705847Z","iopub.execute_input":"2024-12-13T15:24:29.706459Z","iopub.status.idle":"2024-12-13T15:24:29.729776Z","shell.execute_reply.started":"2024-12-13T15:24:29.706421Z","shell.execute_reply":"2024-12-13T15:24:29.728826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_genre.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.732663Z","iopub.execute_input":"2024-12-13T15:24:29.732946Z","iopub.status.idle":"2024-12-13T15:24:29.743267Z","shell.execute_reply.started":"2024-12-13T15:24:29.732921Z","shell.execute_reply":"2024-12-13T15:24:29.742423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_user= pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.user', sep='|', header=None, names=['user_id','age','gender','occupation','zip code'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.744318Z","iopub.execute_input":"2024-12-13T15:24:29.744578Z","iopub.status.idle":"2024-12-13T15:24:29.76362Z","shell.execute_reply.started":"2024-12-13T15:24:29.744553Z","shell.execute_reply":"2024-12-13T15:24:29.762755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_user.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.764703Z","iopub.execute_input":"2024-12-13T15:24:29.765741Z","iopub.status.idle":"2024-12-13T15:24:29.775374Z","shell.execute_reply.started":"2024-12-13T15:24:29.765694Z","shell.execute_reply":"2024-12-13T15:24:29.774604Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Merging tables","metadata":{}},{"cell_type":"markdown","source":"#### Here we will merge all the table in one table so we can see the relationship between users and movies","metadata":{}},{"cell_type":"code","source":"df_merged1 = pd.merge(df, df_user, on='user_id', how='inner')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.77645Z","iopub.execute_input":"2024-12-13T15:24:29.776674Z","iopub.status.idle":"2024-12-13T15:24:29.81743Z","shell.execute_reply.started":"2024-12-13T15:24:29.776651Z","shell.execute_reply":"2024-12-13T15:24:29.816596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.81863Z","iopub.execute_input":"2024-12-13T15:24:29.8189Z","iopub.status.idle":"2024-12-13T15:24:29.830359Z","shell.execute_reply.started":"2024-12-13T15:24:29.818875Z","shell.execute_reply":"2024-12-13T15:24:29.829532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged1.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.83137Z","iopub.execute_input":"2024-12-13T15:24:29.831627Z","iopub.status.idle":"2024-12-13T15:24:29.847433Z","shell.execute_reply.started":"2024-12-13T15:24:29.831603Z","shell.execute_reply":"2024-12-13T15:24:29.846621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged = pd.merge(df_merged1, df_items, on='movie_id', how='inner')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.848447Z","iopub.execute_input":"2024-12-13T15:24:29.848791Z","iopub.status.idle":"2024-12-13T15:24:29.896971Z","shell.execute_reply.started":"2024-12-13T15:24:29.848749Z","shell.execute_reply":"2024-12-13T15:24:29.896084Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Explore the merged data","metadata":{}},{"cell_type":"code","source":"df_merged.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.898095Z","iopub.execute_input":"2024-12-13T15:24:29.898349Z","iopub.status.idle":"2024-12-13T15:24:29.913227Z","shell.execute_reply.started":"2024-12-13T15:24:29.898324Z","shell.execute_reply":"2024-12-13T15:24:29.912161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.914521Z","iopub.execute_input":"2024-12-13T15:24:29.914954Z","iopub.status.idle":"2024-12-13T15:24:29.964002Z","shell.execute_reply.started":"2024-12-13T15:24:29.914918Z","shell.execute_reply":"2024-12-13T15:24:29.963123Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that there are some nan values that we need to clear","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Clean the data","metadata":{}},{"cell_type":"code","source":"df_cleaned = df_merged.dropna(axis=1, how='all')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:29.965042Z","iopub.execute_input":"2024-12-13T15:24:29.965368Z","iopub.status.idle":"2024-12-13T15:24:30.009479Z","shell.execute_reply.started":"2024-12-13T15:24:29.96533Z","shell.execute_reply":"2024-12-13T15:24:30.008583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.010562Z","iopub.execute_input":"2024-12-13T15:24:30.010838Z","iopub.status.idle":"2024-12-13T15:24:30.05023Z","shell.execute_reply.started":"2024-12-13T15:24:30.010812Z","shell.execute_reply":"2024-12-13T15:24:30.049185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned = df_cleaned.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.051436Z","iopub.execute_input":"2024-12-13T15:24:30.05182Z","iopub.status.idle":"2024-12-13T15:24:30.096962Z","shell.execute_reply.started":"2024-12-13T15:24:30.051781Z","shell.execute_reply":"2024-12-13T15:24:30.096097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.09806Z","iopub.execute_input":"2024-12-13T15:24:30.098366Z","iopub.status.idle":"2024-12-13T15:24:30.135525Z","shell.execute_reply.started":"2024-12-13T15:24:30.098336Z","shell.execute_reply":"2024-12-13T15:24:30.134477Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we didn't lost so much data so it's ok to delete the nan values","metadata":{}},{"cell_type":"code","source":"df_cleaned[\"unknown\"].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.13676Z","iopub.execute_input":"2024-12-13T15:24:30.137122Z","iopub.status.idle":"2024-12-13T15:24:30.143956Z","shell.execute_reply.started":"2024-12-13T15:24:30.137084Z","shell.execute_reply":"2024-12-13T15:24:30.142953Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### we see that unknown column has zeros so we should delete it","metadata":{}},{"cell_type":"code","source":"df_cleaned= df_cleaned.drop(columns=['unknown'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.145238Z","iopub.execute_input":"2024-12-13T15:24:30.145604Z","iopub.status.idle":"2024-12-13T15:24:30.164911Z","shell.execute_reply.started":"2024-12-13T15:24:30.145565Z","shell.execute_reply":"2024-12-13T15:24:30.163949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## checking for duplicates","metadata":{}},{"cell_type":"code","source":"duplicate_count = df_cleaned.duplicated().sum()\nprint(f'Number of duplicate rows: {duplicate_count}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.166098Z","iopub.execute_input":"2024-12-13T15:24:30.166431Z","iopub.status.idle":"2024-12-13T15:24:30.253197Z","shell.execute_reply.started":"2024-12-13T15:24:30.166394Z","shell.execute_reply":"2024-12-13T15:24:30.252161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.254214Z","iopub.execute_input":"2024-12-13T15:24:30.254486Z","iopub.status.idle":"2024-12-13T15:24:30.269153Z","shell.execute_reply.started":"2024-12-13T15:24:30.254461Z","shell.execute_reply":"2024-12-13T15:24:30.268242Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Let's convert timestamp to datetime object","metadata":{}},{"cell_type":"code","source":"df_cleaned['timestamp'] = pd.to_datetime(df_cleaned['timestamp'], unit='s') \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.270203Z","iopub.execute_input":"2024-12-13T15:24:30.270517Z","iopub.status.idle":"2024-12-13T15:24:30.287945Z","shell.execute_reply.started":"2024-12-13T15:24:30.270491Z","shell.execute_reply":"2024-12-13T15:24:30.287095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.292981Z","iopub.execute_input":"2024-12-13T15:24:30.293255Z","iopub.status.idle":"2024-12-13T15:24:30.314226Z","shell.execute_reply.started":"2024-12-13T15:24:30.29323Z","shell.execute_reply":"2024-12-13T15:24:30.313278Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### we will merge the data with zip_codes to get more geographical information","metadata":{}},{"cell_type":"code","source":"zip_codes=pd.read_csv(\"/kaggle/input/zipcodes-county-fips-crosswalk/ZIP-COUNTY-FIPS_2017-06.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.315244Z","iopub.execute_input":"2024-12-13T15:24:30.315486Z","iopub.status.idle":"2024-12-13T15:24:30.36709Z","shell.execute_reply.started":"2024-12-13T15:24:30.315461Z","shell.execute_reply":"2024-12-13T15:24:30.366098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zip_codes.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.368249Z","iopub.execute_input":"2024-12-13T15:24:30.36853Z","iopub.status.idle":"2024-12-13T15:24:30.378434Z","shell.execute_reply.started":"2024-12-13T15:24:30.368504Z","shell.execute_reply":"2024-12-13T15:24:30.377356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zip_codes[\"COUNTYNAME\"].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.379562Z","iopub.execute_input":"2024-12-13T15:24:30.379897Z","iopub.status.idle":"2024-12-13T15:24:30.395807Z","shell.execute_reply.started":"2024-12-13T15:24:30.379862Z","shell.execute_reply":"2024-12-13T15:24:30.394973Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### checking for duplicates and nan values","metadata":{}},{"cell_type":"code","source":"zip_codes.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.396811Z","iopub.execute_input":"2024-12-13T15:24:30.397163Z","iopub.status.idle":"2024-12-13T15:24:30.421257Z","shell.execute_reply.started":"2024-12-13T15:24:30.397127Z","shell.execute_reply":"2024-12-13T15:24:30.420352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"duplicate_zips = zip_codes['ZIP'].duplicated().sum()\nprint(f'Number of duplicate ZIP codes: {duplicate_zips}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.422309Z","iopub.execute_input":"2024-12-13T15:24:30.422606Z","iopub.status.idle":"2024-12-13T15:24:30.429766Z","shell.execute_reply.started":"2024-12-13T15:24:30.422572Z","shell.execute_reply":"2024-12-13T15:24:30.42889Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Removing duplicates from zip and merging it with the cleaned data","metadata":{}},{"cell_type":"code","source":"zip_codes = zip_codes.drop_duplicates(subset=['ZIP'])\ndf_cleaned['zip code'] = df_cleaned['zip code'].astype(str) \nzip_codes['ZIP'] = zip_codes['ZIP'].astype(str)\ndf_final = pd.merge(df_cleaned, zip_codes,left_on='zip code',right_on='ZIP', how='inner')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.430894Z","iopub.execute_input":"2024-12-13T15:24:30.431189Z","iopub.status.idle":"2024-12-13T15:24:30.540532Z","shell.execute_reply.started":"2024-12-13T15:24:30.431155Z","shell.execute_reply":"2024-12-13T15:24:30.539563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_final.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.541764Z","iopub.execute_input":"2024-12-13T15:24:30.542119Z","iopub.status.idle":"2024-12-13T15:24:30.548791Z","shell.execute_reply.started":"2024-12-13T15:24:30.542081Z","shell.execute_reply":"2024-12-13T15:24:30.547781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.550397Z","iopub.execute_input":"2024-12-13T15:24:30.55075Z","iopub.status.idle":"2024-12-13T15:24:30.560582Z","shell.execute_reply.started":"2024-12-13T15:24:30.550693Z","shell.execute_reply":"2024-12-13T15:24:30.559739Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### we will add a new feature to calculate the number of dates between release and rating","metadata":{}},{"cell_type":"code","source":"# Calculate time difference between rating date and release date\ndf_final['timestamp'] = pd.to_datetime(df_final['timestamp'], errors='coerce') \ndf_final['release_date'] = pd.to_datetime(df_final['release_date'], errors='coerce')\ndf_final['days_since_release'] = (df_final['timestamp'] - df_final['release_date']).dt.days","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.561668Z","iopub.execute_input":"2024-12-13T15:24:30.561972Z","iopub.status.idle":"2024-12-13T15:24:30.592734Z","shell.execute_reply.started":"2024-12-13T15:24:30.561947Z","shell.execute_reply":"2024-12-13T15:24:30.592069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_final.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.593706Z","iopub.execute_input":"2024-12-13T15:24:30.594008Z","iopub.status.idle":"2024-12-13T15:24:30.613553Z","shell.execute_reply.started":"2024-12-13T15:24:30.59398Z","shell.execute_reply":"2024-12-13T15:24:30.612761Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### we will now extract the release year","metadata":{}},{"cell_type":"code","source":"df_final['year_of_release'] = df_final['release_date'].dt.year","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.614589Z","iopub.execute_input":"2024-12-13T15:24:30.614971Z","iopub.status.idle":"2024-12-13T15:24:30.626572Z","shell.execute_reply.started":"2024-12-13T15:24:30.614926Z","shell.execute_reply":"2024-12-13T15:24:30.625762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_final.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.627612Z","iopub.execute_input":"2024-12-13T15:24:30.627874Z","iopub.status.idle":"2024-12-13T15:24:30.685611Z","shell.execute_reply.started":"2024-12-13T15:24:30.627848Z","shell.execute_reply":"2024-12-13T15:24:30.684767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_final.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.686992Z","iopub.execute_input":"2024-12-13T15:24:30.687418Z","iopub.status.idle":"2024-12-13T15:24:30.706106Z","shell.execute_reply.started":"2024-12-13T15:24:30.687375Z","shell.execute_reply":"2024-12-13T15:24:30.705207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_final['rating'] = pd.to_numeric(df_final['rating'], downcast='unsigned')\ndf_final['age'] = pd.to_numeric(df_final['age'], downcast='unsigned')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.707551Z","iopub.execute_input":"2024-12-13T15:24:30.708233Z","iopub.status.idle":"2024-12-13T15:24:30.722729Z","shell.execute_reply.started":"2024-12-13T15:24:30.708192Z","shell.execute_reply":"2024-12-13T15:24:30.721854Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualisation part","metadata":{}},{"cell_type":"markdown","source":"### Plot 1:the count of ratings by age","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n# Create the countplot\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\nsns.countplot(x='gender', data=df_final, palette='Set2')\n\n# Add title and labels\nplt.title('Countplot by Gender')\nplt.xlabel('Gender')\nplt.ylabel('Count')\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:30.723847Z","iopub.execute_input":"2024-12-13T15:24:30.72415Z","iopub.status.idle":"2024-12-13T15:24:32.135756Z","shell.execute_reply.started":"2024-12-13T15:24:30.724107Z","shell.execute_reply":"2024-12-13T15:24:32.13475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that males have more ratings in this dataset","metadata":{}},{"cell_type":"markdown","source":"### Plot 2: the number of ratings by occupation","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n# Create the countplot\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\nsns.countplot(x='occupation', data=df_final, palette='Set2')\n\n# Add title and labels\nplt.xticks(rotation=90)\nplt.title('Countplot by Gender')\nplt.xlabel('occupation')\nplt.ylabel('Count')\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:32.136817Z","iopub.execute_input":"2024-12-13T15:24:32.137189Z","iopub.status.idle":"2024-12-13T15:24:32.589524Z","shell.execute_reply.started":"2024-12-13T15:24:32.137153Z","shell.execute_reply":"2024-12-13T15:24:32.588731Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that students are the most type who rated in this dataset","metadata":{}},{"cell_type":"markdown","source":"### Plot 3:the number of ratings by movie type","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"movie_type_columns = [ 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western' ]\ndf_movie_types = df_final[movie_type_columns]\nmovie_counts = df_movie_types.sum()\nmovie_counts = movie_counts.reset_index() \nmovie_counts.columns = ['Movie_Type', 'Count'] \n# Plot the counts using Seaborn \nsns.set(style=\"whitegrid\") \nplt.figure(figsize=(14, 8)) \nsns.barplot(x='Movie_Type', y='Count', data=movie_counts, palette='Set2') \n# Add title and labels\nplt.xticks(rotation=90)\nplt.title('Count of Movie Types') \nplt.xlabel('Movie Type') \nplt.ylabel('Count') \n# Rotate x-axis labels for better readability plt.xticks(rotation=45) \n# Show the plot \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:32.590803Z","iopub.execute_input":"2024-12-13T15:24:32.591392Z","iopub.status.idle":"2024-12-13T15:24:32.942729Z","shell.execute_reply.started":"2024-12-13T15:24:32.591351Z","shell.execute_reply":"2024-12-13T15:24:32.941892Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that the top 3 are drama,comedy and action","metadata":{}},{"cell_type":"markdown","source":"### Plot 4:the number of users by age","metadata":{}},{"cell_type":"code","source":"# Plot the distribution of user ages\nplt.figure(figsize=(10, 6))\nsns.histplot(df_final['age'], bins=10, kde=True)\nplt.title('Distribution of User Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:32.943951Z","iopub.execute_input":"2024-12-13T15:24:32.944544Z","iopub.status.idle":"2024-12-13T15:24:33.561427Z","shell.execute_reply.started":"2024-12-13T15:24:32.944505Z","shell.execute_reply":"2024-12-13T15:24:33.560553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Define age groups\nbins = [0, 18, 25, 35, 45, 50, 56, 100]\nlabels = ['<18', '18-24', '25-34', '35-44', '45-49', '50-55', '56+']\ndf_final['age_group'] = pd.cut(df_final['age'], bins=bins, labels=labels, right=False, include_lowest=True)\n\n# Plot the count of users by age group and gender\nplt.figure(figsize=(14, 8))\nsns.countplot(x='age_group', hue='gender', data=df_final, palette='Set2')\nplt.title('User Demographics by Age Group and Gender')\nplt.xlabel('Age Group')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:33.562652Z","iopub.execute_input":"2024-12-13T15:24:33.563028Z","iopub.status.idle":"2024-12-13T15:24:33.928609Z","shell.execute_reply.started":"2024-12-13T15:24:33.562987Z","shell.execute_reply":"2024-12-13T15:24:33.927783Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that young people are the majortity in this dataset","metadata":{}},{"cell_type":"markdown","source":"### Plot 5: the most ratings given in this dataset","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Remove infinite values\ndf_final = df_final.replace([np.inf, -np.inf], np.nan).dropna(subset=['rating'])\n\n# Plot the distribution of ratings\nplt.figure(figsize=(10, 6))\nsns.histplot(df_final['rating'], bins=10, kde=True)\nplt.title('Distribution of Movie Ratings')\nplt.xlabel('Rating')\nplt.ylabel('Frequency')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:33.929903Z","iopub.execute_input":"2024-12-13T15:24:33.930513Z","iopub.status.idle":"2024-12-13T15:24:34.795098Z","shell.execute_reply.started":"2024-12-13T15:24:33.930473Z","shell.execute_reply":"2024-12-13T15:24:34.794258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that rating 4 is the most common rating in this dataset","metadata":{}},{"cell_type":"markdown","source":"### Plot 6:the number of ratings by gender","metadata":{}},{"cell_type":"code","source":"\n# Plot the ratings by genre\nplt.figure(figsize=(14, 8))\nsns.boxplot(x='gender', y='rating', data=df_final, palette='Set2')\nplt.title('Ratings by Genre')\nplt.xlabel('Genre')\nplt.ylabel('Rating')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:34.796146Z","iopub.execute_input":"2024-12-13T15:24:34.796387Z","iopub.status.idle":"2024-12-13T15:24:35.10111Z","shell.execute_reply.started":"2024-12-13T15:24:34.796362Z","shell.execute_reply":"2024-12-13T15:24:35.100229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that both gender have the same distribution","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### plot 7:the top 20 rated movies","metadata":{}},{"cell_type":"code","source":"# Count the number of ratings for each movie\npopular_movies = df_final['movie_title'].value_counts().reset_index()\npopular_movies.columns = ['Movie Title', 'Count']\n\n# Plot the most popular movies\nplt.figure(figsize=(14, 8))\nsns.barplot(x='Count', y='Movie Title', data=popular_movies.head(20), palette='Set2')\nplt.title('Top 20 Most Rated Movies')\nplt.xlabel('Number of Ratings')\nplt.ylabel('Movie Title')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:35.102161Z","iopub.execute_input":"2024-12-13T15:24:35.102541Z","iopub.status.idle":"2024-12-13T15:24:35.627554Z","shell.execute_reply.started":"2024-12-13T15:24:35.10251Z","shell.execute_reply":"2024-12-13T15:24:35.626781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Plot 8:the highest rated movies","metadata":{}},{"cell_type":"code","source":"# Calculate the average rating for each movie\navg_ratings = df_final.groupby('movie_title')['rating'].mean().reset_index()\navg_ratings.columns = ['Movie Title', 'Average Rating']\n\n# Plot the top 20 highest rated movies\nplt.figure(figsize=(14, 8))\nsns.barplot(x='Average Rating', y='Movie Title', data=avg_ratings.nlargest(20, 'Average Rating'), palette='Set2')\nplt.title('Top 20 Highest Rated Movies')\nplt.xlabel('Average Rating')\nplt.ylabel('Movie Title')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:35.628812Z","iopub.execute_input":"2024-12-13T15:24:35.629459Z","iopub.status.idle":"2024-12-13T15:24:36.047442Z","shell.execute_reply.started":"2024-12-13T15:24:35.629418Z","shell.execute_reply":"2024-12-13T15:24:36.046569Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we cannot take so much information from that plot given that a movie can be rated only once 5","metadata":{}},{"cell_type":"markdown","source":"### Plot 9:Average rating for each genre","metadata":{}},{"cell_type":"code","source":"\nmovie_genre_columns = [\n    'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n    'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', \n    'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n]\n\n# Calculate average ratings for each genre\ngenre_ratings = {}\nfor genre in movie_genre_columns:\n    genre_ratings[genre] = df_final.loc[df_final[genre] == 1, 'rating'].mean()\n\n# Convert the dictionary to a DataFrame for plotting\ngenre_ratings_df = pd.DataFrame(list(genre_ratings.items()), columns=['Genre', 'Average Rating'])\n\n# Plot the average ratings for each genre\nplt.figure(figsize=(14, 8))\nsns.barplot(x='Genre', y='Average Rating', data=genre_ratings_df, palette='Set2')\nplt.title('Average Ratings for Each Genre')\nplt.xlabel('Genre')\nplt.ylabel('Average Rating')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:36.048673Z","iopub.execute_input":"2024-12-13T15:24:36.04902Z","iopub.status.idle":"2024-12-13T15:24:36.409356Z","shell.execute_reply.started":"2024-12-13T15:24:36.048985Z","shell.execute_reply":"2024-12-13T15:24:36.40859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that war and drama have the highest rating average","metadata":{}},{"cell_type":"markdown","source":"### Plot 10:Average rating by genre for each gender","metadata":{}},{"cell_type":"code","source":"\n# List of columns representing movie genres\nmovie_genre_columns = [\n    'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n    'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', \n    'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n]\n\n# Calculate average ratings for each genre by gender\ngenre_ratings_male = {}\ngenre_ratings_female = {}\n\nfor genre in movie_genre_columns:\n    genre_ratings_male[genre] = df_final.loc[(df_final[genre] == 1) & (df_final['gender'] == 'M'), 'rating'].mean()\n    genre_ratings_female[genre] = df_final.loc[(df_final[genre] == 1) & (df_final['gender'] == 'F'), 'rating'].mean()\n\n# Convert the dictionaries to DataFrames for plotting\ngenre_ratings_male_df = pd.DataFrame(list(genre_ratings_male.items()), columns=['Genre', 'Average Rating (Male)'])\ngenre_ratings_female_df = pd.DataFrame(list(genre_ratings_female.items()), columns=['Genre', 'Average Rating (Female)'])\n\n# Plot the average ratings for each genre by gender\nfig, axes = plt.subplots(2, 1, figsize=(14, 16), sharex=True)\n\nsns.barplot(ax=axes[0], x='Genre', y='Average Rating (Male)', data=genre_ratings_male_df, palette='Blues_d')\naxes[0].set_title('Average Ratings for Each Genre by Male Users')\naxes[0].set_xlabel('')\naxes[0].set_ylabel('Average Rating')\naxes[0].tick_params(axis='x', rotation=45)\n\nsns.barplot(ax=axes[1], x='Genre', y='Average Rating (Female)', data=genre_ratings_female_df, palette='Reds_d')\naxes[1].set_title('Average Ratings for Each Genre by Female Users')\naxes[1].set_xlabel('Genre')\naxes[1].set_ylabel('Average Rating')\naxes[1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:36.410804Z","iopub.execute_input":"2024-12-13T15:24:36.411076Z","iopub.status.idle":"2024-12-13T15:24:37.428874Z","shell.execute_reply.started":"2024-12-13T15:24:36.411048Z","shell.execute_reply":"2024-12-13T15:24:37.427988Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### we see that both male and female like film-noir and war the most ","metadata":{}},{"cell_type":"code","source":"df_final[\"gender\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:37.430009Z","iopub.execute_input":"2024-12-13T15:24:37.43028Z","iopub.status.idle":"2024-12-13T15:24:37.441173Z","shell.execute_reply.started":"2024-12-13T15:24:37.430254Z","shell.execute_reply":"2024-12-13T15:24:37.440373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Function to plot genre preferences by occupation\ndef plot_genre_preferences(genre_list, title):\n    genre_ratings = []\n    for genre in genre_list:\n        ratings = df_final[df_final[genre] == 1].groupby('occupation')['rating'].mean().reset_index()\n        ratings['Genre'] = genre\n        genre_ratings.append(ratings)\n    \n    genre_ratings_df = pd.concat(genre_ratings, ignore_index=True)\n\n    plt.figure(figsize=(14, 8))\n    sns.barplot(x='Genre', y='rating', hue='occupation', data=genre_ratings_df, palette='Set2')\n    plt.title(title)\n    plt.xlabel('Genre')\n    plt.ylabel('Average Rating')\n    plt.legend(title='Occupation')\n    plt.show()\n\n# Define genre groups\ngenre_groups = {\n    'Group 1: Action, Adventure, Animation, Children\\'s, Comedy': ['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy'],\n    'Group 2: Crime, Documentary, Drama, Fantasy, Film-Noir': ['Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir'],\n    'Group 3: Horror, Musical, Mystery, Romance, Sci-Fi': ['Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi'],\n    'Group 4: Thriller, War, Western': ['Thriller', 'War', 'Western']\n}\n\n# Plot each group\nfor title, genres in genre_groups.items():\n    plot_genre_preferences(genres, title)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:37.442531Z","iopub.execute_input":"2024-12-13T15:24:37.443185Z","iopub.status.idle":"2024-12-13T15:24:41.200238Z","shell.execute_reply.started":"2024-12-13T15:24:37.443143Z","shell.execute_reply":"2024-12-13T15:24:41.199411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define age groups\nbins = [0, 18, 25, 35, 45, 50, 56, 100]\nlabels = ['<18', '18-24', '25-34', '35-44', '45-49', '50-55', '56+']\ndf_final['age_group'] = pd.cut(df_final['age'], bins=bins, labels=labels, right=False, include_lowest=True)\n\n# Function to plot genre preferences by age group\ndef plot_genre_preferences(genre_list, title):\n    genre_ratings = []\n    for genre in genre_list:\n        ratings = df_final[df_final[genre] == 1].groupby('age_group', observed=True)['rating'].mean().reset_index()\n        ratings['Genre'] = genre\n        genre_ratings.append(ratings)\n    \n    genre_ratings_df = pd.concat(genre_ratings, ignore_index=True)\n\n    plt.figure(figsize=(14, 8))\n    sns.barplot(x='Genre', y='rating', hue='age_group', data=genre_ratings_df, palette='Set2')\n    plt.title(title)\n    plt.xlabel('Genre')\n    plt.ylabel('Average Rating')\n    plt.legend(title='Age Group')\n    plt.xticks(rotation=45)\n    plt.show()\n\n# Define genre groups\ngenre_groups = {\n    'Group 1: Action, Adventure, Animation, Children\\'s, Comedy': ['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy'],\n    'Group 2: Crime, Documentary, Drama, Fantasy, Film-Noir': ['Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir'],\n    'Group 3: Horror, Musical, Mystery, Romance, Sci-Fi': ['Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi'],\n    'Group 4: Thriller, War, Western': ['Thriller', 'War', 'Western']\n}\n\n# Plot each group\nfor title, genres in genre_groups.items():\n    plot_genre_preferences(genres, title)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:41.20139Z","iopub.execute_input":"2024-12-13T15:24:41.201755Z","iopub.status.idle":"2024-12-13T15:24:43.228229Z","shell.execute_reply.started":"2024-12-13T15:24:41.201687Z","shell.execute_reply":"2024-12-13T15:24:43.227416Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Implementing collaborative filtering system","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\n# Assuming the dataframe is already loaded as df_final\n\n# Create user-item interaction matrix\ninteraction_matrix = df_final.pivot(index='user_id', columns='movie_id', values='rating').fillna(0).values\n\n# Useful Values\nnum_movies, num_users = interaction_matrix.shape\nnum_features = 50  # Adjusted to accommodate new features\n\n# User Metadata\nuser_metadata = df_final[['age', 'gender', 'occupation']]\n\n# Item Metadata (Genres)\nitem_metadata = df_final[['movie_id', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n                          'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n                          'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']].drop_duplicates(subset=['movie_id']).set_index('movie_id')\n\n# Encode categorical features\nencoder = OneHotEncoder(sparse=False)\nencoded_gender = encoder.fit_transform(user_metadata[['gender']])\nencoded_occupation = encoder.fit_transform(user_metadata[['occupation']])\n\n# Combine user features\nuser_features = np.hstack((user_metadata[['age']].values, encoded_gender, encoded_occupation))\nscaler_user = StandardScaler()\nuser_features_normalized = scaler_user.fit_transform(user_features)\n\n# Combine item features\nitem_features = item_metadata.values\nscaler_item = StandardScaler()\nitem_features_normalized = scaler_item.fit_transform(item_features)\n\n# Set Initial Parameters (W, X), use tf.Variable to track these variables\ntf.random.set_seed(1234) # for consistent results\nW = tf.Variable(tf.random.normal((num_users, num_features), dtype=tf.float64), name='W')\nX = tf.Variable(tf.random.normal((num_movies, num_features), dtype=tf.float64), name='X')\nb = tf.Variable(tf.random.normal((1, num_users), dtype=tf.float64), name='b')\n\n# Instantiate an optimizer\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\n# Define the loss function with L2 regularization\nlambda_reg = 0.01  # Adjusted regularization strength\n\ndef loss_fn():\n    pred = tf.matmul(X, W, transpose_b=True) + b\n    mask = tf.cast(interaction_matrix > 0, dtype=tf.float64)\n    error = mask * (interaction_matrix - pred)\n    loss = tf.reduce_sum(tf.square(error))\n    reg_loss = lambda_reg * (tf.reduce_sum(tf.square(W)) + tf.reduce_sum(tf.square(X)))\n    return loss + reg_loss\n\n# Function to train the model\ndef train_model(epochs=500):\n    for epoch in range(epochs):\n        with tf.GradientTape() as tape:\n            loss = loss_fn()\n        gradients = tape.gradient(loss, [W, X, b])\n        optimizer.apply_gradients(zip(gradients, [W, X, b]))\n        if (epoch + 1) % 50 == 0:\n            print(f'Epoch {epoch + 1}, Loss: {loss.numpy()}')\n\n# K-Fold Cross Validation\nkf = KFold(n_splits=5)\nr2_scores = []\nrmse_scores = []\nmae_scores = []\n\nfor train_index, test_index in kf.split(interaction_matrix):\n    train_data, test_data = interaction_matrix[train_index], interaction_matrix[test_index]\n    \n    # Reset variables\n    W.assign(tf.random.normal((num_users, num_features), dtype=tf.float64))\n    X.assign(tf.random.normal((num_movies, num_features), dtype=tf.float64))\n    b.assign(tf.random.normal((1, num_users), dtype=tf.float64))\n    \n    # Train the model\n    train_model(epochs=500)\n    \n    # Make predictions\n    pred = tf.matmul(X, W, transpose_b=True) + b\n    \n    # Flatten predictions and true ratings for evaluation\n    true_ratings = test_data[test_data > 0]\n    predicted_ratings = pred.numpy()[test_index][test_data > 0]\n    \n    # Calculate evaluation metrics\n    r2 = r2_score(true_ratings, predicted_ratings)\n    rmse = mean_squared_error(true_ratings, predicted_ratings, squared=False)\n    mae = mean_absolute_error(true_ratings, predicted_ratings)\n    \n    r2_scores.append(r2)\n    rmse_scores.append(rmse)\n    mae_scores.append(mae)\n\n# Average scores\navg_r2 = np.mean(r2_scores)\navg_rmse = np.mean(rmse_scores)\navg_mae = np.mean(mae_scores)\n\nprint(f'Average R² Score across folds: {avg_r2}')\nprint(f'Average RMSE across folds: {avg_rmse}')\nprint(f'Average MAE across folds: {avg_mae}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:24:43.229776Z","iopub.execute_input":"2024-12-13T15:24:43.230139Z","iopub.status.idle":"2024-12-13T15:25:55.977571Z","shell.execute_reply.started":"2024-12-13T15:24:43.230101Z","shell.execute_reply":"2024-12-13T15:25:55.976656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Implementing based content recommondation system","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\n# Assuming the dataframe is already loaded as df_final\n\n# Item Metadata (Genres and other attributes)\nitem_metadata = df_final[['movie_id', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n                          'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n                          'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', 'year_of_release']].drop_duplicates(subset=['movie_id']).set_index('movie_id')\n\n# Normalize numerical features (e.g., year_of_release)\nscaler_item = StandardScaler()\nitem_metadata[['year_of_release']] = scaler_item.fit_transform(item_metadata[['year_of_release']])\n\n# User Metadata\nuser_metadata = df_final[['user_id', 'age', 'gender', 'occupation']].drop_duplicates(subset=['user_id']).set_index('user_id')\n\n# Encode categorical features\nencoder = OneHotEncoder(sparse=False)\nencoded_gender = encoder.fit_transform(user_metadata[['gender']])\nencoded_occupation = encoder.fit_transform(user_metadata[['occupation']])\n\n# Combine user features\nuser_features = np.hstack((user_metadata[['age']].values, encoded_gender, encoded_occupation))\nscaler_user = StandardScaler()\nuser_features_normalized = scaler_user.fit_transform(user_features)\n\n# Combine item features\nitem_features = item_metadata.values\nscaler_item = StandardScaler()\nitem_features_normalized = scaler_item.fit_transform(item_features)\n\n# Convert to sparse matrices\nitem_features_sparse = csr_matrix(item_features_normalized)\nuser_features_sparse = csr_matrix(user_features_normalized)\n\n# Compute cosine similarity matrices for users and items in batches\ndef compute_similarity_in_batches_sparse(features, batch_size=500):\n    num_items = features.shape[0]\n    similarity_matrix = np.zeros((num_items, num_items))\n    \n    for start in range(0, num_items, batch_size):\n        end = min(start + batch_size, num_items)\n        batch_features = features[start:end].toarray()\n        similarity_matrix[start:end] = cosine_similarity(batch_features, features.toarray())\n    \n    return similarity_matrix\n\nuser_sim_matrix = compute_similarity_in_batches_sparse(user_features_sparse)\nitem_sim_matrix = compute_similarity_in_batches_sparse(item_features_sparse)\n\n# Function to predict ratings based on content-based similarity\ndef predict_ratings(user_id, movie_id):\n    # Find similar movies\n    movie_idx = item_metadata.index.get_loc(movie_id)\n    sim_scores = item_sim_matrix[movie_idx]\n    sim_scores[movie_idx] = 0  # Exclude the movie itself\n\n    # Get top similar movies\n    top_similar_indices = np.argsort(-sim_scores)[:5]  # Top 5 similar movies\n    top_similar_movies = item_metadata.iloc[top_similar_indices].index\n\n    # Get actual ratings for these similar movies by the user\n    actual_ratings = df_final[(df_final['user_id'] == user_id) & (df_final['movie_id'].isin(top_similar_movies))]['rating']\n\n    if not actual_ratings.empty:\n        # Predict the rating as the average rating of the top similar movies\n        predicted_rating = actual_ratings.mean()\n    else:\n        # If no similar movies have been rated, use the average rating of the user\n        predicted_rating = df_final[df_final['user_id'] == user_id]['rating'].mean()\n\n    return predicted_rating\n\n# Evaluate the model using R²\ndef evaluate_model(df_final):\n    true_ratings = []\n    predicted_ratings = []\n\n    for index, row in df_final.iterrows():\n        user_id = row['user_id']\n        movie_id = row['movie_id']\n        true_rating = row['rating']\n        predicted_rating = predict_ratings(user_id, movie_id)\n\n        true_ratings.append(true_rating)\n        predicted_ratings.append(predicted_rating)\n\n    r2 = r2_score(true_ratings, predicted_ratings)\n    rmse = mean_squared_error(true_ratings, predicted_ratings, squared=False)\n    mae = mean_absolute_error(true_ratings, predicted_ratings)\n    \n    return r2, rmse, mae\n\n# Example usage\nr2, rmse, mae = evaluate_model(df_final)\nprint(f'R² Score: {r2}')\nprint(f'RMSE: {rmse}')\nprint(f'MAE: {mae}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:25:55.97883Z","iopub.execute_input":"2024-12-13T15:25:55.979344Z","iopub.status.idle":"2024-12-13T15:30:02.178841Z","shell.execute_reply.started":"2024-12-13T15:25:55.979315Z","shell.execute_reply":"2024-12-13T15:30:02.177873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Implementing hybrid filtering system","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\nfrom scipy.sparse.linalg import svds\n\n# Create user-item interaction matrix\ninteraction_matrix = df_final.pivot(index='user_id', columns='movie_id', values='rating').fillna(0).values\ninteraction_matrix_sparse = csr_matrix(interaction_matrix)\n\n# Perform SVD\nU, sigma, Vt = svds(interaction_matrix_sparse, k=50)\n\n# Reconstruct the original matrix\nsigma = np.diag(sigma)\npredicted_ratings = np.dot(np.dot(U, sigma), Vt)\n\n# Function to predict ratings using a hybrid approach\ndef hybrid_predict_ratings(user_id, movie_id):\n    # Content-based similarity\n    movie_idx = item_metadata.index.get_loc(movie_id)\n    sim_scores = item_sim_matrix[movie_idx]\n    sim_scores[movie_idx] = 0  # Exclude the movie itself\n\n    # Get top similar movies\n    top_similar_indices = np.argsort(-sim_scores)[:5]  # Top 5 similar movies\n    top_similar_movies = item_metadata.iloc[top_similar_indices].index\n\n    # Content-based prediction\n    actual_ratings = df_final[(df_final['user_id'] == user_id) & (df_final['movie_id'].isin(top_similar_movies))]['rating']\n    if not actual_ratings.empty:\n        content_pred_rating = actual_ratings.mean()\n    else:\n        content_pred_rating = df_final[df_final['user_id'] == user_id]['rating'].mean()\n\n    # Collaborative prediction\n    user_idx = user_metadata.index.get_loc(user_id)\n    collaborative_pred_rating = predicted_ratings[user_idx, movie_idx]\n\n    # Hybrid prediction\n    hybrid_pred_rating = (content_pred_rating + collaborative_pred_rating) / 2\n    return hybrid_pred_rating\n\n# Evaluate the hybrid model\ndef evaluate_hybrid_model(df_final):\n    true_ratings = []\n    predicted_ratings = []\n\n    for index, row in df_final.iterrows():\n        user_id = row['user_id']\n        movie_id = row['movie_id']\n        true_rating = row['rating']\n        predicted_rating = hybrid_predict_ratings(user_id, movie_id)\n\n        true_ratings.append(true_rating)\n        predicted_ratings.append(predicted_rating)\n\n    r2 = r2_score(true_ratings, predicted_ratings)\n    rmse = mean_squared_error(true_ratings, predicted_ratings, squared=False)\n    mae = mean_absolute_error(true_ratings, predicted_ratings)\n    \n    return r2, rmse, mae\n\n# Example usage\nr2, rmse, mae = evaluate_hybrid_model(df_final)\nprint(f'Hybrid R² Score: {r2}')\nprint(f'Hybrid RMSE: {rmse}')\nprint(f'Hybrid MAE: {mae}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T15:30:02.180043Z","iopub.execute_input":"2024-12-13T15:30:02.180311Z","iopub.status.idle":"2024-12-13T15:34:07.332157Z","shell.execute_reply.started":"2024-12-13T15:30:02.180286Z","shell.execute_reply":"2024-12-13T15:34:07.331259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}